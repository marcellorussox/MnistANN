{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analisi delle varianti di Rprop per la classificazione del dataset MNIST\n",
    "Il presente quaderno Jupyter fornisce un ambiente interattivo per l'esplorazione e l'addestramento di reti neurali per il riconoscimento delle cifre del dataset MNIST. Con questo quaderno, gli utenti possono:\n",
    "\n",
    "\n",
    "### Sperimentare con diverse configurazioni di Reti Neurali\n",
    "Il quaderno offre la flessibilità di sperimentare con una vasta gamma di configurazioni di reti neurali. Gli utenti possono definire il numero di strati nascosti, il numero di neuroni per strato e le funzioni di attivazione desiderate per costruire la loro rete neurale.\n",
    "\n",
    "\n",
    "### Personalizzare i parametri di addestramento\n",
    "Gli utenti possono personalizzare i parametri di addestramento come il numero di epoche, il tasso di apprendimento e la suddivisione del set di addestramento. Inoltre, possono specificare il numero di run, ovvero quante volte desiderano ripetere l'addestramento per una determinata configurazione di rete e algoritmo di ottimizzazione.\n",
    "\n",
    "\n",
    "### Testare diversi algoritmi di ottimizzazione Rprop\n",
    "Il quaderno include implementazioni di diversi algoritmi di ottimizzazione, tra cui varianti di Rprop come Rprop-, Rprop+, iRprop-, e iRprop+. Gli utenti possono confrontare le prestazioni delle reti neurali addestrate con questi diversi algoritmi di ottimizzazione.\n",
    "\n",
    "\n",
    "### Valutare le Prestazioni delle Reti Neurali\n",
    "Il quaderno fornisce un'analisi dettagliata delle prestazioni delle reti neurali addestrate, inclusi l'errore sui set di addestramento e di validazione, l'accuratezza sui set di addestramento, di validazione e di test e il tempo di esecuzione. Inoltre, vengono calcolate la media e la varianza delle metriche di prestazione su più run, consentendo agli utenti di valutare la stabilità e la consistenza delle configurazioni di rete e algoritmi di ottimizzazione.\n",
    "\n",
    "\n",
    "## Contenuti\n",
    "1. Estrazione e preparazione del dataset MNIST\n",
    "2. Creazione delle reti neurali originarie\n",
    "3. Addestramento delle reti neurali con diverse varianti di Rprop\n",
    "4. Valutazione delle prestazioni attraverso grafici\n",
    "5. Test delle reti addestrate su immagini del test set\n",
    "\n",
    "\n",
    "N.B: la variabile *number_of_runs* deve essere maggiore di 0.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from uninaannpy import neural_network as nn\n",
    "from uninaannpy import error_functions as ef\n",
    "from uninaannpy import activation_functions as af\n",
    "from uninaannpy import datasets as ds\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Legge csv con pandas\n",
    "train_data = pd.read_csv('data/mnist_train.csv')\n",
    "test_data = pd.read_csv('data/mnist_test.csv')\n",
    "\n",
    "# Ottiene array per il training e il test\n",
    "train_array = np.array(train_data)\n",
    "test_array = np.array(test_data)\n",
    "\n",
    "# Estrapola il numero di righe e di colonne di train e test\n",
    "train_rows, train_cols = train_array.shape \n",
    "test_rows, test_cols = test_array.shape  \n",
    "\n",
    "# Mescola casualmente i dati prima di suddividerli in set di sviluppo e training\n",
    "np.random.shuffle(train_array)  \n",
    "#Calcola percentuale dati per il validation set\n",
    "validation_percentage = 0.20\n",
    "val_index = int(np.ceil(train_rows * validation_percentage))\n",
    "\n",
    "# Distribuzione training, validation e test set\n",
    "train_X, train_Y = ds.get_mnist_training(train_array, val_index)\n",
    "validation_X, validation_Y = ds.get_mnist_validation(train_array, val_index)\n",
    "test_X, test_Y = ds.get_mnist_test(test_array)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T21:30:19.468157Z",
     "start_time": "2024-05-22T21:30:16.838927Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Creazione rete neurale\n",
    "\n",
    "# Assegna funzioni di attivazione per ogni strato della rete\n",
    "hidden_activation_functions = [af.leaky_relu, af.leaky_relu, af.tanh]\n",
    "\n",
    "# Assegna numero di neuroni per ogni strato\n",
    "hidden_layers = [80, 80, 80]\n",
    "# Assegna della funzione di attivazione e di errore per l'ultimo strato della rete\n",
    "output_activation_function = af.identity\n",
    "error_function = ef.cross_entropy_softmax\n",
    "\n",
    "# Estrae dimensione input e target\n",
    "input_layer_size = train_X.shape[0]\n",
    "output_layer_size = train_Y.shape[0]\n",
    "\n",
    "epochs = 35\n",
    "learning_rate = 0.00001\n",
    "number_of_runs = 5 # Deve essere maggiore di 0!\n",
    "\n",
    "nets = []\n",
    "\n",
    "for i in range(number_of_runs):\n",
    "    try:\n",
    "        net = nn.NeuralNetwork(hidden_activation_functions, output_activation_function, error_function,\n",
    "                    input_layer_size, hidden_layers, output_layer_size)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error during initialization: {e}\")\n",
    "    nets.append(net)\n",
    "    hidden_activation_functions = hidden_activation_functions[:-1]\n",
    "\n",
    "print(\"Architettura delle reti:\\n\")\n",
    "nets[0].get_net_structure()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T21:30:19.481119Z",
     "start_time": "2024-05-22T21:30:19.470833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architettura delle reti:\n",
      "\n",
      "Numero di strati nascosti: 3\n",
      "Dimensione dell'input: 784\n",
      "Dimensione dell'output: 10\n",
      "Neuroni negli strati nascosti: 80, 80, 80\n",
      "Funzioni di attivazione: leaky_relu, leaky_relu, tanh, identity\n",
      "Funzione di errore: cross_entropy_softmax\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "from uninaannpy.neural_network import RpropType\n",
    "\n",
    "# Inizializza una lista vuota per memorizzare i risultati\n",
    "std_metrics_list = []\n",
    "std_trained_nets = []\n",
    "\n",
    "for i in range(number_of_runs):\n",
    "    std_training_net = nets[i].duplicate_network()\n",
    "    \n",
    "    print('\\n\\n\\nRun numero', i + 1, '\\n')\n",
    "    # Batch training Rprop standard\n",
    "    std_metrics = std_training_net.train_neural_network(train_X, train_Y, validation_X, validation_Y, epochs=epochs, learning_rate=learning_rate, rprop_type=RpropType.STANDARD)\n",
    "    std_trained_nets.append(std_training_net)\n",
    "    std_metrics_list.append(std_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-22T21:30:19.482314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Run numero 1 \n",
      "\n",
      "\n",
      "Epoca: 0/35   Rprop utilizzata: RpropType.STANDARD\n",
      "    Training Accuracy: 0.14329,       Training Loss: 110152.22457;\n",
      "    Validation Accuracy: 0.14568,     Validation Loss: 27539.30465\n",
      "\n",
      "\n",
      "Epoca: 1/35   Rprop utilizzata: RpropType.STANDARD\n",
      "    Training Accuracy: 0.28886,       Training Loss: 103940.80118;\n",
      "    Validation Accuracy: 0.29152,     Validation Loss: 26004.51184\n",
      "\n",
      "\n",
      "Epoca: 2/35   Rprop utilizzata: RpropType.STANDARD\n",
      "    Training Accuracy: 0.15871,       Training Loss: 176857.22125;\n",
      "    Validation Accuracy: 0.15051,     Validation Loss: 44617.78652\n",
      "\n",
      "\n",
      "Epoca: 3/35   Rprop utilizzata: RpropType.STANDARD\n",
      "    Training Accuracy: 0.09725,       Training Loss: 301957.47896;\n",
      "    Validation Accuracy: 0.09784,     Validation Loss: 74810.31849\n",
      "\n",
      "\n",
      "Epoca: 4/35   Rprop utilizzata: RpropType.STANDARD\n",
      "    Training Accuracy: 0.11144,       Training Loss: 357468.26142;\n",
      "    Validation Accuracy: 0.11609,     Validation Loss: 88784.27899\n",
      "\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "std_metrics_mean, std_metrics_variance, std_last_metrics_mean, std_last_metrics_variance = nn.metrics_mean_variance(std_metrics_list, epochs, number_of_runs)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Stampa accuracy per training e test set\n",
    "std_test_accuracies = []\n",
    "std_test_accuracy_mean, std_test_accuracy_variance = 0, 0\n",
    "\n",
    "for run in range(number_of_runs):\n",
    "    std_test_accuracies.append(std_trained_nets[run].print_accuracies(f'\\nTest Rprop- Run {run + 1}', test_X, test_Y, train_X, train_Y))\n",
    "    \n",
    "# Calcola la media\n",
    "std_test_accuracy_mean = np.mean(std_test_accuracies)\n",
    "# Calcola la varianza\n",
    "std_test_accuracy_variance = np.var(std_test_accuracies)\n",
    "# Calcola la varianza normalizzata rispetto alla media\n",
    "std_test_accuracy_variance = std_test_accuracy_variance / std_test_accuracy_mean"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Costruzione della stringa per il file di output\n",
    "csv_string_std = '0,'+ (':'.join(map(str, hidden_layers))) + ','\n",
    "csv_string_std += str(number_of_runs) + ',' + ','.join(map(str, std_last_metrics_mean)) + ',' + ','.join(map(str, std_last_metrics_variance)) + f',{round(std_test_accuracy_mean, 5)},{round(std_test_accuracy_variance, 5)}\\n'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from uninaannpy.neural_network import RpropType\n",
    "\n",
    "# Inizializzo una lista vuota per memorizzare i risultati\n",
    "plus_metrics_list = []\n",
    "plus_trained_nets = []\n",
    "\n",
    "for i in range(number_of_runs):\n",
    "    plus_training_net = nets[i].duplicate_network()\n",
    "    \n",
    "    print('\\n\\n\\nRun numero', i + 1, '\\n')\n",
    "    # Batch training Rprop con weight-backtracking\n",
    "    plus_metrics = plus_training_net.train_neural_network(train_X, train_Y, validation_X, validation_Y, epochs=epochs, learning_rate=learning_rate, rprop_type=RpropType.RPROP_PLUS)\n",
    "    plus_trained_nets.append(plus_training_net)\n",
    "    plus_metrics_list.append(plus_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "plus_metrics_mean, plus_metrics_variance, plus_last_metrics_mean, plus_last_metrics_variance = nn.metrics_mean_variance(plus_metrics_list, epochs, number_of_runs)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Stampa accuracy per training e test set\n",
    "plus_test_accuracies = []\n",
    "plus_test_accuracy_mean, plus_test_accuracy_variance = 0, 0\n",
    "\n",
    "for run in range(number_of_runs):\n",
    "    plus_test_accuracies.append(plus_trained_nets[run].print_accuracies(f'\\nTest Rprop+ Run {run + 1}', test_X, test_Y, train_X, train_Y))\n",
    "    \n",
    "# Calcola la media\n",
    "plus_test_accuracy_mean = np.mean(plus_test_accuracies)\n",
    "# Calcola la varianza\n",
    "plus_test_accuracy_variance = np.var(plus_test_accuracies)\n",
    "# Calcola la varianza normalizzata rispetto alla media\n",
    "plus_test_accuracy_variance = plus_test_accuracy_variance / plus_test_accuracy_mean"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Costruzione della stringa per il file di output\n",
    "csv_string_plus = '1,'+ (':'.join(map(str, hidden_layers))) + ','\n",
    "csv_string_plus += str(number_of_runs) + ',' + ','.join(map(str, plus_last_metrics_mean)) + ',' + ','.join(map(str, plus_last_metrics_variance)) + f',{round(plus_test_accuracy_mean, 5)},{round(plus_test_accuracy_variance, 5)}\\n'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from uninaannpy.neural_network import RpropType\n",
    "\n",
    "# Inizializza una lista vuota per memorizzare i risultati\n",
    "istd_metrics_list = []\n",
    "istd_trained_nets = []\n",
    "\n",
    "for i in range(number_of_runs):\n",
    "    istd_training_net = nets[i].duplicate_network()\n",
    "    \n",
    "    print('\\n\\n\\nRun numero', i + 1, '\\n')\n",
    "    # Batch training improved Rprop\n",
    "    istd_metrics = istd_training_net.train_neural_network(train_X, train_Y, validation_X, validation_Y, epochs=epochs, learning_rate=learning_rate, rprop_type=RpropType.IRPROP)\n",
    "    istd_trained_nets.append(istd_training_net)\n",
    "    istd_metrics_list.append(istd_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "istd_metrics_mean, istd_metrics_variance, istd_last_metrics_mean, istd_last_metrics_variance = nn.metrics_mean_variance(istd_metrics_list, epochs, number_of_runs)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Stampa accuracy per training e test set\n",
    "istd_test_accuracies = []\n",
    "istd_test_accuracy_mean, istd_test_accuracy_variance = 0, 0\n",
    "\n",
    "for run in range(number_of_runs):\n",
    "    istd_test_accuracies.append(istd_trained_nets[run].print_accuracies(f'\\nTest iRprop- Run {run + 1}', test_X, test_Y, train_X, train_Y))\n",
    "    \n",
    "# Calcola la media\n",
    "istd_test_accuracy_mean = np.mean(istd_test_accuracies)\n",
    "# Calcola la varianza\n",
    "istd_test_accuracy_variance = np.var(istd_test_accuracies)\n",
    "# Calcola la varianza normalizzata rispetto alla media\n",
    "istd_test_accuracy_variance = istd_test_accuracy_variance / istd_test_accuracy_mean"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Costruzione della stringa per il file di output\n",
    "csv_string_istd = '2,'+ (':'.join(map(str, hidden_layers))) + ','\n",
    "csv_string_istd += str(number_of_runs) + ',' + ','.join(map(str, istd_last_metrics_mean)) + ',' + ','.join(map(str, istd_last_metrics_variance)) + f',{round(istd_test_accuracy_mean, 5)},{round(istd_test_accuracy_variance, 5)}\\n'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from uninaannpy.neural_network import RpropType\n",
    "\n",
    "# Inizializza una lista vuota per memorizzare i risultati\n",
    "iplus_metrics_list = []\n",
    "iplus_nets = []\n",
    "iplus_trained_nets = []\n",
    "\n",
    "for i in range(number_of_runs):\n",
    "    iplus_training_net = nets[i].duplicate_network()\n",
    "    \n",
    "    print('\\n\\n\\nRun numero', i + 1, '\\n')\n",
    "    # Batch training improved Rprop con weight-backtracking\n",
    "    iplus_metrics = iplus_training_net.train_neural_network(train_X, train_Y, validation_X, validation_Y, epochs=epochs, learning_rate=learning_rate, rprop_type=RpropType.IRPROP_PLUS)\n",
    "    iplus_metrics_list.append(iplus_metrics)\n",
    "    iplus_trained_nets.append(iplus_training_net)\n",
    "    iplus_metrics_list.append(iplus_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "iplus_metrics_mean, iplus_metrics_variance, iplus_last_metrics_mean, iplus_last_metrics_variance = nn.metrics_mean_variance(iplus_metrics_list, epochs, number_of_runs)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Stampa accuracy per training e test set\n",
    "iplus_test_accuracies = []\n",
    "iplus_test_accuracy_mean, iplus_test_accuracy_variance = 0, 0\n",
    "\n",
    "for run in range(number_of_runs):\n",
    "    iplus_test_accuracies.append(plus_trained_nets[run].print_accuracies(f'\\nTest iRprop+ Run {run + 1}', test_X, test_Y, train_X, train_Y))\n",
    "    \n",
    "# Calcola la media\n",
    "iplus_test_accuracy_mean = np.mean(iplus_test_accuracies)\n",
    "# Calcola la varianza\n",
    "iplus_test_accuracy_variance = np.var(iplus_test_accuracies)\n",
    "# Calcola la varianza normalizzata rispetto alla media\n",
    "iplus_test_accuracy_variance = iplus_test_accuracy_variance / iplus_test_accuracy_mean"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Costruzione della stringa per il file di output\n",
    "csv_string_iplus = '3,'+ (':'.join(map(str, hidden_layers))) + ','\n",
    "csv_string_iplus += str(number_of_runs) + ',' + ','.join(map(str, iplus_last_metrics_mean)) + ',' + ','.join(map(str, iplus_last_metrics_variance)) + f',{round(iplus_test_accuracy_mean, 5)},{round(iplus_test_accuracy_variance, 5)}\\n'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Stampo grafico dell'errore medio del train set\n",
    "plt.figure()\n",
    "plt.plot(std_metrics_mean[0], 'b', label='RPROP-')\n",
    "plt.plot(plus_metrics_mean[0], 'r', label='RPROP+')\n",
    "plt.plot(istd_metrics_mean[0], 'y', label='IRPROP-')\n",
    "plt.plot(iplus_metrics_mean[0], 'g', label='IRPROP+')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Errore')\n",
    "plt.title(f'Errore medio sul training set\\nNeuroni: {', '.join(map(str, hidden_layers))} Runs: {number_of_runs}')\n",
    "plt.legend()\n",
    "plt.xlim(0, epochs)\n",
    "\n",
    "# Salvo il plot come file PNG\n",
    "plt.savefig(f'plots/{','.join(map(str, hidden_layers))}_train_err_mean_{number_of_runs}runs.png')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Stampo grafico della varianza dell'errore del train set\n",
    "plt.figure()\n",
    "plt.plot(std_metrics_variance[0], 'b', label='RPROP-')\n",
    "plt.plot(plus_metrics_variance[0], 'r', label='RPROP+')\n",
    "plt.plot(istd_metrics_variance[0], 'y', label='IRPROP-')\n",
    "plt.plot(iplus_metrics_variance[0], 'g', label='IRPROP+')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Var(Errore)')\n",
    "plt.title(f'Varianza dell\\'errore sul training set\\nNeuroni: {', '.join(map(str, hidden_layers))} Runs: {number_of_runs}')\n",
    "plt.legend()\n",
    "plt.xlim(0, epochs)\n",
    "\n",
    "# Salvo il plot come file PNG\n",
    "plt.savefig(f'plots/{','.join(map(str, hidden_layers))}_train_err_var_{number_of_runs}runs.png')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Stampa grafico dell'errore medio del validation set\n",
    "plt.figure()\n",
    "plt.plot(std_metrics_mean[1], 'b', label='RPROP-')\n",
    "plt.plot(plus_metrics_mean[1], 'r', label='RPROP+')\n",
    "plt.plot(istd_metrics_mean[1], 'y', label='IRPROP-')\n",
    "plt.plot(iplus_metrics_mean[1], 'g', label='IRPROP+')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Errore')\n",
    "plt.title(f'Errore medio sul validation set\\nNeuroni: {', '.join(map(str, hidden_layers))} Runs: {number_of_runs}')\n",
    "plt.legend()\n",
    "plt.xlim(0, epochs)\n",
    "\n",
    "# Salva il plot come file PNG\n",
    "plt.savefig(f'plots/{','.join(map(str, hidden_layers))}_val_err_mean_{number_of_runs}runs.png')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Stampa grafico della varianza dell'errore del validation set\n",
    "plt.figure()\n",
    "plt.plot(std_metrics_variance[1], 'b', label='RPROP-')\n",
    "plt.plot(plus_metrics_variance[1], 'r', label='RPROP+')\n",
    "plt.plot(istd_metrics_variance[1], 'y', label='IRPROP-')\n",
    "plt.plot(iplus_metrics_variance[1], 'g', label='IRPROP+')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Var(Errore)')\n",
    "plt.title(f'Varianza dell\\'errore sul validation set\\nNeuroni: {', '.join(map(str, hidden_layers))} Runs: {number_of_runs}')\n",
    "plt.legend()\n",
    "plt.xlim(0, epochs)\n",
    "\n",
    "# Salva il plot come file PNG\n",
    "plt.savefig(f'plots/{','.join(map(str, hidden_layers))}_val_err_var_{number_of_runs}runs.png')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Stampa grafico dell'accuratezza media del train set\n",
    "plt.figure()\n",
    "plt.plot(std_metrics_mean[2], 'b', label='RPROP-')\n",
    "plt.plot(plus_metrics_mean[2], 'r', label='RPROP+')\n",
    "plt.plot(istd_metrics_mean[2], 'y', label='IRPROP-')\n",
    "plt.plot(iplus_metrics_mean[2], 'g', label='IRPROP+')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Accuratezza')\n",
    "plt.title(f'Accuratezza media sul training set\\nNeuroni: {', '.join(map(str, hidden_layers))} Runs: {number_of_runs}')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, epochs)\n",
    "\n",
    "# Salva il plot come file PNG\n",
    "plt.savefig(f'plots/{','.join(map(str, hidden_layers))}_train_acc_mean_{number_of_runs}runs.png')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Stampa grafico della varianza dell'accuratezza del train set\n",
    "plt.figure()\n",
    "plt.plot(std_metrics_variance[2], 'b', label='RPROP-')\n",
    "plt.plot(plus_metrics_variance[2], 'r', label='RPROP+')\n",
    "plt.plot(istd_metrics_variance[2], 'y', label='IRPROP-')\n",
    "plt.plot(iplus_metrics_variance[2], 'g', label='IRPROP+')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Var(Accuratezza)')\n",
    "plt.title(f'Varianza dell\\'accuratezza sul training set\\nNeuroni: {', '.join(map(str, hidden_layers))} Runs: {number_of_runs}')\n",
    "plt.legend()\n",
    "plt.xlim(0, epochs)\n",
    "\n",
    "# Salva il plot come file PNG\n",
    "plt.savefig(f'plots/{','.join(map(str, hidden_layers))}_train_acc_var_{number_of_runs}runs.png')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Stampa grafico dell'accuratezzaa media del validation set\n",
    "plt.figure()\n",
    "plt.plot(std_metrics_mean[3],  'b', label='RPROP-')\n",
    "plt.plot(plus_metrics_mean[3], 'r', label='RPROP+')\n",
    "plt.plot(istd_metrics_mean[3], 'y', label='IRPROP-')\n",
    "plt.plot(iplus_metrics_mean[3], 'g', label='IRPROP+')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Accuratezza')\n",
    "plt.title(f'Accuratezza media sul validation set\\nNeuroni: {', '.join(map(str, hidden_layers))} Runs: {number_of_runs}')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(0, epochs)\n",
    "\n",
    "# Salva il plot come file PNG\n",
    "plt.savefig(f'plots/{','.join(map(str, hidden_layers))}_val_acc_mean_{number_of_runs}runs.png')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Stampa grafico della varianza dell'accuratezza del validation set\n",
    "plt.figure()\n",
    "plt.plot(std_metrics_variance[3],  'b', label='RPROP-')\n",
    "plt.plot(plus_metrics_variance[3], 'r', label='RPROP+')\n",
    "plt.plot(istd_metrics_variance[3], 'y', label='IRPROP-')\n",
    "plt.plot(iplus_metrics_variance[3], 'g', label='IRPROP+')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Var(Accuratezza)')\n",
    "plt.title(f'Varianza dell\\'accuratezza sul validation set\\nNeuroni: {', '.join(map(str, hidden_layers))} Runs: {number_of_runs}')\n",
    "plt.legend()\n",
    "plt.xlim(0, epochs)\n",
    "\n",
    "# Salva il plot come file PNG\n",
    "plt.savefig(f'plots/{','.join(map(str, hidden_layers))}_val_acc_var_{number_of_runs}runs.png')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Scrive le stringhe nel CSV\n",
    "with open(\"data/runs_mean_variance.csv\", \"a\") as file:\n",
    "     file.write(csv_string_std)\n",
    "     file.write(csv_string_plus)\n",
    "     file.write(csv_string_istd)\n",
    "     file.write(csv_string_iplus)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Predizione rete addestrata con Rprop- (standard)\n",
    "image = 7777\n",
    "\n",
    "print('Test Rprop-')\n",
    "std_training_net.test_prediction(image, test_X)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Predizione rete addestrata con Rprop+ (Rprop con weight-backtracking)\n",
    "image = 8000\n",
    "\n",
    "print('Test Rprop+')\n",
    "plus_training_net.test_prediction(image, test_X)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Predizione rete addestrata con iRprop- (Improved Rprop)\n",
    "image = 8000\n",
    "\n",
    "print('Test iRprop-')\n",
    "istd_training_net.test_prediction(image, test_X)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Predizione rete addestrata con iRprop+ (Improved Rprop con weight-backtracking)\n",
    "image = 8000\n",
    "\n",
    "print('Test iRprop+')\n",
    "iplus_training_net.test_prediction(image, test_X)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
