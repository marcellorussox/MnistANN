{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Analisi delle varianti di RProp per la classificazione del dataset MNIST\n",
    "\n",
    "## Introduzione\n",
    "\n",
    "In questo quaderno, esploreremo le prestazioni di diverse varianti dell'algoritmo di ottimizzazione RProp (Resilient Backpropagation) applicate alla classificazione del famoso dataset MNIST. Il dataset MNIST è un insieme di immagini di cifre scritte a mano, ampiamente utilizzato come benchmark nell'ambito dell'apprendimento automatico e del riconoscimento di pattern.\n",
    "\n",
    "## Obiettivo\n",
    "\n",
    "L'obiettivo principale di questo studio è valutare le prestazioni di diverse varianti di RProp nell'addestramento di reti neurali artificiali per la classificazione del dataset MNIST. In particolare, esploreremo:\n",
    "\n",
    "- RProp standard (RProp-)\n",
    "- RProp con backtracking dei pesi (RProp+)\n",
    "- Improved RProp (iRProp-)\n",
    "- Improved RProp con backtracking dei pesi (iRProp+)\n",
    "\n",
    "Per ciascuna variante di RProp, addestreremo una rete neurale artificiale originaria e ne valuteremo le prestazioni attraverso grafici che mostrano l'andamento dell'errore e della precisione sia sul set di addestramento che sul set di validazione. Infine, testeremo le reti addestrate su un set di test e visualizzeremo le probabilità predette per alcune immagini del dataset.\n",
    "\n",
    "## Contenuti\n",
    "\n",
    "1. Estrazione e preparazione del dataset MNIST\n",
    "2. Creazione della rete neurale originaria\n",
    "3. Addestramento delle reti neurali con diverse varianti di RProp\n",
    "4. Valutazione delle prestazioni attraverso grafici\n",
    "5. Test delle reti addestrate su nuove immagini\n",
    "6. Conclusioni e osservazioni finali\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from uninaannpy import neural_network as nn\n",
    "from uninaannpy import error_functions as ef\n",
    "from uninaannpy import activation_functions as af\n",
    "from uninaannpy import datasets as ds\n",
    "from uninaannpy import utility as ut\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Lettura csv con pandas\n",
    "train_data = pd.read_csv('data/mnist_train.csv')\n",
    "test_data = pd.read_csv('data/mnist_test.csv')\n",
    "\n",
    "#Ottenimento array per il training e il testing\n",
    "train_array = np.array(train_data)\n",
    "test_array = np.array(test_data)\n",
    "\n",
    "#Estrapoliamo il numero di righe e di colonne di train e test\n",
    "train_rows, train_cols = train_array.shape \n",
    "test_rows, test_cols = test_array.shape  \n",
    "\n",
    "#Mescola casualmente i dati prima di suddividerli in set di sviluppo e training\n",
    "np.random.shuffle(train_array)  \n",
    "#Calcolo percentuale dati per il validation set\n",
    "validation_percentage = 0.20\n",
    "val_index = int(np.ceil(train_rows * validation_percentage))\n",
    "\n",
    "#Distribuzione training, validation e test set\n",
    "train_in, train_labels = ds.get_mnist_training(train_array, train_rows, train_cols, val_index)\n",
    "validation_in, validation_labels = ds.get_mnist_validation(train_array, train_cols, val_index)\n",
    "test_in, test_labels = ds.get_mnist_testing(test_array, test_cols, test_rows)\n",
    "\n",
    "#Creazione rete neurale\n",
    "#Assegnazione funzioni di attivazione per ogni strato della rete\n",
    "hidden_activation_functions = [af.tanh]\n",
    "\n",
    "#Assegnazione numero di neuroni per ogni strato\n",
    "hidden_layers = [100]\n",
    "#Assegnazione della funzione di attivazione e di errore per l'ultimo strato della rete\n",
    "output_activation_function = af.identity\n",
    "error_function = ef.cross_entropy_softmax\n",
    "\n",
    "#Estrazione input e target\n",
    "input_layer_size = train_in.shape[0]\n",
    "output_layer_size = train_labels.shape[0]\n",
    "net = nn.NeuralNetwork(hidden_activation_functions, output_activation_function, error_function,\n",
    "                input_layer_size, hidden_layers, output_layer_size)\n",
    "\n",
    "#Copia la rete principale in quattro per il training\n",
    "std_training_net = net.duplicate_network()\n",
    "plus_training_net = net.duplicate_network()\n",
    "istd_training_net = net.duplicate_network()\n",
    "iplus_training_net = net.duplicate_network()\n",
    "\n",
    "std_training_net.get_net_structure()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from uninaannpy.neural_network import RPropType\n",
    "\n",
    "# Batch training rProp standard\n",
    "std_train_err, std_validation_err, std_train_accuracy, std_validation_accuracy = std_training_net.train_neural_network(train_in, train_labels, validation_in, validation_labels, epochs=40, learning_rate=0.00001, rprop_type=RPropType.STANDARD)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from uninaannpy.neural_network import RPropType\n",
    "\n",
    "# Batch training rProp con weight-backtracking\n",
    "plus_train_err, plus_validation_err, plus_train_accuracy, plus_validation_accuracy = plus_training_net.train_neural_network(train_in, train_labels, validation_in, validation_labels, epochs=40, learning_rate=0.00001, rprop_type=RPropType.RPROP_PLUS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from uninaannpy.neural_network import RPropType\n",
    "\n",
    "# Batch training improved rProp con weight-backtracking\n",
    "istd_train_err, istd_validation_err, istd_train_accuracy, istd_validation_accuracy = istd_training_net.train_neural_network(train_in, train_labels, validation_in, validation_labels, epochs=40, learning_rate=0.00001, rprop_type=RPropType.IRPROP)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from uninaannpy.neural_network import RPropType\n",
    "\n",
    "# Batch training improved rProp\n",
    "iplus_train_err, iplus_validation_err, iplus_train_accuracy, iplus_validation_accuracy = iplus_training_net.train_neural_network(train_in, train_labels, validation_in, validation_labels, epochs=40, learning_rate=0.00001, rprop_type=RPropType.IRPROP_PLUS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Stampa grafico dell'errore del training\n",
    "plt.figure()\n",
    "plt.plot(std_train_err, 'b', label='RPROP-')\n",
    "plt.plot(plus_train_err, 'r', label='RPROP+')\n",
    "plt.plot(istd_train_err, 'y', label='IRPROP-')\n",
    "plt.plot(iplus_train_err, 'g', label='IRPROP+')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Errori')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Stampa grafico dell'errore del validation\n",
    "plt.figure()\n",
    "plt.plot(std_validation_err, 'b', label='RPROP-')\n",
    "plt.plot(plus_validation_err, 'r', label='RPROP+')\n",
    "plt.plot(istd_validation_err, 'y', label='IRPROP-')\n",
    "plt.plot(iplus_validation_err, 'g', label='IRPROP+')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Errori')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Stampa grafico della precisione del training\n",
    "plt.figure()\n",
    "plt.plot(std_train_accuracy, 'b', label='RPROP-')\n",
    "plt.plot(plus_train_accuracy, 'r', label='RPROP+')\n",
    "plt.plot(istd_train_accuracy, 'y', label='IRPROP-')\n",
    "plt.plot(iplus_train_accuracy, 'g', label='IRPROP+')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Precisione')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Stampa grafico della precisione del validation\n",
    "plt.figure()\n",
    "plt.plot(std_validation_accuracy, 'b', label='RPROP-')\n",
    "plt.plot(plus_validation_accuracy, 'r', label='RPROP+')\n",
    "plt.plot(istd_validation_accuracy, 'y', label='IRPROP-')\n",
    "plt.plot(iplus_validation_accuracy, 'g', label='IRPROP+')\n",
    "plt.xlabel('Epoche')\n",
    "plt.ylabel('Precisione')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Stampa accuracy per training e test set\n",
    "\n",
    "std_training_net.print_accuracies('Test RProp-', test_in, test_labels, train_in, train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Stampa accuracy per training e test set\n",
    "\n",
    "plus_training_net.print_accuracies('Test RProp+', test_in, test_labels, train_in, train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Stampa accuracy per training e test set\n",
    "\n",
    "istd_training_net.print_accuracies('Test iRProp-', test_in, test_labels, train_in, train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Stampa accuracy per training e test set\n",
    "\n",
    "iplus_training_net.print_accuracies('Test iRProp+', test_in, test_labels, train_in, train_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Predizione rete senza addestramento e rete addestrata\n",
    "image = 47993\n",
    "\n",
    "print('Test rProp-')\n",
    "ut.test_prediction(net, std_training_net, image, train_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Predizione rete senza addestramento e rete addestrata\n",
    "image = 47993\n",
    "\n",
    "print('Test rProp+')\n",
    "ut.test_prediction(net, plus_training_net, image, train_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Predizione rete senza addestramento e rete addestrata\n",
    "image = 47993\n",
    "\n",
    "print('Test irProp-')\n",
    "ut.test_prediction(net, istd_training_net, image, train_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Predizione rete senza addestramento e rete addestrata\n",
    "image = 47993\n",
    "\n",
    "print('Test irProp+')\n",
    "ut.test_prediction(net, iplus_training_net, image, train_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
